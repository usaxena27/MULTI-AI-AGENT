from typing import Any, List, Union

from langchain_groq import ChatGroq
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import create_agent

from app.config.settings import settings


def get_response_from_ai_agents(
    llm_id: str,
    query: Union[str, List[Any]],
    allow_search: bool,
    system_prompt: str,
) -> str:
    """
    Run the multi-AI agent and return the final AI response as text.

    Args:
        llm_id:       Model name/id (e.g. "llama-3.1-70b-versatile")
        query:        Either a single user query string OR a list (from frontend)
        allow_search: Whether to enable Tavily search tool
        system_prompt: System instructions for the agent

    Returns:
        The last AI message content as a string.
    """

    # Initialize Groq LLM (GROQ_API_KEY must be set in env or settings)
    llm = ChatGroq(model=llm_id)

    # Optional web search tool
    tools = [TavilySearchResults(max_results=2)] if allow_search else []

    # âœ… New LangChain agent API: use `system_prompt`, not `state_modifier`
    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=system_prompt or "You are a helpful multi-agent AI assistant.",
    )

    # --- Build the messages state in the correct format ---
    # UI is currently sending: "messages": [user_query]
    # So here we support both string and list input.
    if isinstance(query, list):
        # If already in role/content format, keep as is
        if query and isinstance(query[0], dict) and "role" in query[0]:
            messages_state = query
        else:
            # Treat list items as separate user messages
            messages_state = [
                {"role": "user", "content": str(q)} for q in query
            ]
    else:
        # Single query string
        messages_state = [{"role": "user", "content": str(query)}]

    state = {"messages": messages_state}

    # Invoke the agent (non-streaming)
    response_state = agent.invoke(state)

    messages = response_state.get("messages", [])

    if not messages:
        return "No response generated by the agent."

    # Try to get the last assistant/AI message
    last_msg = messages[-1]

    # Case 1: dict-style messages: {"role": "assistant", "content": "..."}
    if isinstance(last_msg, dict):
        return last_msg.get("content", "")

    # Case 2: LangChain BaseMessage objects (AIMessage, etc.)
    content = getattr(last_msg, "content", None)
    if content is not None:
        return content

    # Fallback
    return str(last_msg)
